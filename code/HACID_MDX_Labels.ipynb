{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f260340-5e08-4a28-bb55-afefc29ed5ba",
   "metadata": {},
   "source": [
    "#Â Generating the knowledge graph for medical diagnostics\n",
    "\n",
    "## Preliminaries \n",
    "We import required libraries, select the folder that contains data, and we define global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7278f3-0f06-4727-8e7a-ba6c5f9ea499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "from rdflib import Graph, URIRef, Literal, Namespace, RDFS\n",
    "\n",
    "os.chdir('/Volumes/GoogleDrive/My Drive/SNOMED-CT/Snapshot/Terminology')\n",
    "\n",
    "MDX = Namespace('https://w3id.org/hacid/onto/mdx/')\n",
    "MDXD = Namespace('https://w3id.org/hacid/mdx/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e06f7-6ef9-42b7-84f4-a1150e010398",
   "metadata": {},
   "source": [
    "## Loading dataframes from input tabular data\n",
    "We read the file ```sct2_Relationship_Snapshot_INT_20230630``` that contains all the relations among terms in SNOMED-CT.\n",
    "\n",
    "This file will be used for generating the ontology modules and populating those modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f765117-faf6-4a98-bd95-abb7bc666a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = pd.read_csv('sct2_Relationship_Snapshot_INT_20230630.txt', delimiter='\\t', na_filter=False, dtype=str)\n",
    "relations = relations[relations['active']=='1']\n",
    "#print(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cea2c9-866a-4b70-87ea-1a8323bd5e86",
   "metadata": {},
   "source": [
    "Then, we read the file ```sct2_Description_Snapshot-en_INT_20230630.txt``` that contains all the descriptions (i.e. labels) of clinical terms in SNOMED-CT. \n",
    "\n",
    "From the list of descriptions we keep only those that are marked as active (i.e. the field _active = 1_)\n",
    "\n",
    "In this file we are interested with the columns _id_, _conceptId_, _term_, and _typeId_, as:\n",
    " * _id_ idetifies uniquely the association of the clinical term with the description;\n",
    " * _conceptId_ identifies the clinical term;\n",
    " * _term_ is the label;\n",
    " * _typeId_ is the code that distinguishes between fully specified names (i.e. 900000000000003001) and synomyms (i.e. 900000000000013009)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8d441a-005d-4e4e-ad6b-71cb32245b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = pd.read_csv('sct2_Description_Snapshot-en_INT_20230630.txt', delimiter='\\t', na_filter=False, dtype=str)\n",
    "descriptions = descriptions[descriptions['active'] == '1']\n",
    "descriptions = descriptions[['id', 'conceptId', 'term', 'typeId']]\n",
    "\n",
    "#print(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8313d13-8390-43df-99f6-c88a28685d44",
   "metadata": {},
   "source": [
    "Now we read the file ```der2_cRefset_LanguageSnapshot-en_INT_20230630.txt``` that contains language reference sets. Basically, it allows to distinguish between preferred and alternative labels according to a give language. \n",
    "\n",
    "From the orginal fields avaible when reading the dataframe we only keep the following:\n",
    " * _refsetId_ that identified the reference set. As we are using the interational edition of SNOMED-CT only two reference sets are available, that is US Enghish (i.e. 900000000000509007) and Great Britain English (i.e. 900000000000508004);\n",
    " * _referencedComponentId_ that is the identifier of the association of a clinical term with a given description in the file ```sct2_Relationship_Snapshot_INT_20230630.txt```;\n",
    " * _acceptabilityId_ that allows to distinguish between preferred labels (i.e. 900000000000548007) and alternative ones (i.e. 900000000000549004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0aca29-88db-4c4f-91f2-c483081ade4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "refset = pd.read_csv('der2_cRefset_LanguageSnapshot-en_INT_20230630.txt', delimiter='\\t', na_filter=False, dtype=str)\n",
    "refset = refset[refset['active'] == '1' ][['refsetId', 'referencedComponentId', 'acceptabilityId']]\n",
    "#print(refset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65370419-2e8e-4ecc-abe9-5697284bdbaf",
   "metadata": {},
   "source": [
    "## Terms with language sets\n",
    "We create a dataframe that joins definitions and language sets.\n",
    "This dataframe is then used for deriving fully specified names, preferred terms among synomyms, and alternative terms among synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fabbdc2-855b-42b2-9539-fa29851d61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = descriptions.merge(refset, how='left', left_on='id', right_on='referencedComponentId')\n",
    "\n",
    "fsn = terms[(terms['typeId'] == '900000000000003001') & (terms['acceptabilityId'] == '900000000000548007')]\n",
    "fsn = fsn[['conceptId', 'term', 'refsetId']]\n",
    "#print(fsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247573c-0ef5-433e-b907-66bcbceb5649",
   "metadata": {},
   "source": [
    "Then we derive a dataframe for preferred synonyms, i.e. _typeId_=900000000000013009 and _acceptabilityId_= 900000000000548007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4ae40a-0dc2-413b-b437-ba1c8b00eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefs = terms[(terms['typeId'] == '900000000000013009') & (terms['acceptabilityId'] == '900000000000548007')]\n",
    "prefs = prefs[['conceptId', 'term', 'refsetId']]\n",
    "#print(prefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151839f-82ff-4571-8299-36a5931e3c13",
   "metadata": {},
   "source": [
    "Finally, we derive a dataframe for alternative synonyms, i.e. _typeId_=900000000000013009 and _acceptabilityId_= 900000000000549004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba86961-69ca-4d6f-b294-7f7f36b0d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alts = terms[(terms['typeId'] == '900000000000013009') & (terms['acceptabilityId'] == '900000000000549004')]\n",
    "alts = alts[['conceptId', 'term', 'refsetId']]\n",
    "#print(alts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff6f65-6684-47d3-9b13-a76cf3da3240",
   "metadata": {},
   "source": [
    "## RDF Graphs production\n",
    "\n",
    "We now generate the RDF graphs and we save them with a N-Triples serialisation.\n",
    "\n",
    "We start from the fully specified names, that are associated to terms both with the property MDX.fullySpecifiedName and RDFS.label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89fad10-e942-4743-9b21-8f04820fb77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrea/my-python3-env/lib/python3.11/site-packages/rdflib/plugins/serializers/nt.py:35: UserWarning: NTSerializer always uses UTF-8 encoding. Given encoding was: None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ncadb7ff13a704b19825f340c741f43af (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_triple(row, property: URIRef) -> tuple[URIRef, URIRef, Literal]:\n",
    "    # us-en\n",
    "    if row[2] == '900000000000509007':\n",
    "        return (MDXD[row[0]], property, Literal(row[1], lang='en-us'))\n",
    "    # gb-en\n",
    "    else:\n",
    "        return (MDXD[row[0]], property, Literal(row[1], lang='en-gb'))\n",
    "        \n",
    "g = Graph()\n",
    "\n",
    "triples = [to_triple(row, MDX.fullySpecifiedName) for row in fsn.to_numpy()]\n",
    "for triple in triples:\n",
    "  g.add(triple)\n",
    "\n",
    "triples = [to_triple(row, RDFS.label) for row in fsn.to_numpy()]\n",
    "for triple in triples:\n",
    "  g.add(triple)\n",
    "\n",
    "g.serialize(destination='MDX Knowledge Graph/full-specified-names.nt', format='nt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c47d9de-39bc-48a4-af6e-59e0805fbedf",
   "metadata": {},
   "source": [
    "Now is the turn of preferred synomyms, which are associated to terms both with the property MDX.fullySpecifiedName and RDFS.label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263e6e20-a30d-409e-9707-e473853d1f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N265fdc5c2a694ceabac712a4a19e1fff (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "triples = [to_triple(row, MDX.preferredSynonym) for row in prefs.to_numpy()]\n",
    "for triple in triples:\n",
    "  g.add(triple)\n",
    "\n",
    "g.serialize(destination='MDX Knowledge Graph/preferred-synonyms.nt', format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9112cec-b4b8-47f1-a297-e0b7969621bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Na6b620518ae94275b9e5e6352c68b527 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "triples = [to_triple(row, MDX.alternativeSynonym) for row in alts.to_numpy()]\n",
    "for triple in triples:\n",
    "  g.add(triple)\n",
    "\n",
    "g.serialize(destination='MDX Knowledge Graph/alternative-synonyms.nt', format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20d3ed-08cd-40a4-8adb-0b01a836706d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
